# 读写分离

## 为何要做读写分离？
大部分互联网公司的网站是读多写少，针对这种情况，可以写一个主库，主库挂多个从库，然后从多个从库来读，这样就可以支撑更高的读并发压力。
可以解决以下问题：
1. 线性提升数据库读性能
2. 消除读写锁冲突来提升数据库写性能
3. 冗余从库实现数据的读高可用
需要注意的是：这个架构中，数据库的主库依然是单点的。

## mysql的主从复制是如何实现的？
主库将变更写入binlog日志，从库有一个IO线程将主库的binlog日志拷贝到自己本地，然后写入relay中继日志，接着从库中有一个sql线程会从中继日志读取binlog，然后执行binlog日志中的内容，也就是在自己本地再次执行一遍sql，这样就可以保证自己和主库的数据是一样的。

## 如何解决主从同步延迟问题？
因为主库的数据落地后是通过binlog同步给从库，这里会有一点延时是正常的，但如果延迟较为严重，可以有以下方案：
1. 将一个主库拆分为多个主库，这样每个主库的写并发就减少了几倍。
2. 写代码的时候要注意，插入数据后立马查询有可能查不到。
3. 如果确实需要立马就能查的到，可以只针对这个查询设置直连主库。


---


# 分库分表

## 为什么要进行分库分表
单机硬件资源、连接数、磁盘IO都存在瓶颈
分库分表其实就是为了解决两个问题，一是高并发，二是数据量大。
单表数据量越大，sql的性能会越差，mysql一般超过500w数据就要考虑分表。mysql并发超过1000就要考虑扩容了。

## 水平切分，到底是分库还是分表
强烈建议分库，而不是分表，因为：
1. 分表依然共用一个数据库文件，仍然有磁盘IO的竞争。
2. 分库能够很容易的将数据迁移到不同数据库实例，甚至数据库机器上，扩展性更好。

## 分库分表中间件
1. sharding-jdbc
client层方案，优点为不用部署，运维成本低，不需要代理层的二次转发请求，性能很高，但各个系统会和sharding-jdbc有耦合。

2. mycat
proxy层方案，优点为对各个项目是透明的，升级的话只需要升级中间件，但需要单独部署，运维成本较高。

## 水平拆分和垂直拆分
1. 水平拆分
把一个表的数据弄到多个库的多个表里去，每个库的表结构相同，只是每个库表存放的数据不同，所有库表数据加起来为全部数据。
水平拆分可以将数据均匀放在多个库里，用多个库来扛更高的并发，用多个库的容量进行扩容。

2. 垂直拆分
把一个有很多字段的表拆分成多个表，或者多个库上去。每个库表结构都不一样，每个库表都包含部分字段。一般来说，会将访问频率不同的字段分开存放。因为数据库是有缓存的，你访问频率高的行字段越少，就可以在缓存里缓存更多的行，性能就越高。

## 现在有一个未分库分表的系统，未来要分库分表，如何设计可以方便切换？

1. 停机迁移

停机维护，使用导数工具，将单库单表写到分库分表。

2. 双写迁移方案

在线上系统里面，之前所有写库的地方，增删改操作，除了对老库增删改之外，都加上对新库的增删改，这就是所谓的双写，同时写老库和新库。系统部署之后，使用导数工具读老库数据写新库，导完一轮之后，有可能数据还是存在不一致，我们可以使用程序做一轮校验，然后再读再写，直到最终一致。数据一致后，使用分库分表的代码重新部署一次。


## 如何设计一个可以平滑扩容的分库分表方案？

采用双倍扩容策略，避免数据迁移。扩容前每个节点的数据，有一半要迁移至一个新增节点中，对应关系比较简单，具体操作如下（假设已有2个节点A1、B1，要双倍扩容至A1、A2、B1、B2这四个节点）
1. 无需停止应用服务器
2. 新增两个数据库A2、B2作为从库，设置主从同步关系为：A1-A2、B1-B2，直至主从数据同步完毕
3. 调整分片规则并使之生效
- 原ID % 2 = 0 --> A1 改为 ID % 4 = 0 --> A1，ID % 4 = 2 --> A2
- 原ID % 2 = 1 --> B1 改为 ID % 4 = 1 --> B1，ID % 4 = 3 --> B2
4. 解除数据库实例的主从同步关系，并使之生效
5. 此时四个节点的数据都已完整，只是有冗余，因为多存了和自己配对的节点的那部分数据，择机删除即可，不影响业务。

## 分库分表后如何进行JOIN操作？

对于多库，出于性能考虑，不建议使用mysql自带的join，可以用以下方案避免跨节点join：
1. 全局表：一些稳定的公用数据表，在每个数据库中都保存一份。
2. 字段冗余（反范式）：一些常用的公用字段，在每个数据库中都保存一份。
3. 应用组装：应用获取数据后再进行拼装。


---

## 关于数据库的优化
1.不要用null字段
2.不要用外键
3.不要用select *
4.改写or为union，改写or为in
5.使用union all而不是union
6.字符集编码统一使用utf8mb4


## 关于mysql优化的一些实践
### 反向条件查询不能走索引
```
select from order where status != 0 and status != 1;
```
not in、 not exists都不是好习惯，可以优化为in查询
```
select from order where status in (0, 1);
```

### 前导模糊查询不能使用索引
```
select from order where desc like '%XX';
```
而非前导模糊查询可以
```
select from order where desc like 'XX%';
```

### 数据区分度不大的字段不宜使用索引
```
select from user where sex = 1;
```
原因：性别只有男、女，每次过滤的数据很少，不宜使用索引
从经验上，能过滤80%数据时就可以使用索引。对于订单状态，如果状态值很少，不宜使用索引，如果状态值很多，能够过滤大量的数据，则应该建立索引。

### 在属性上进行计算不能命中索引
```
select from order where year(date) <= '2017';
```
即使data上建立了索引，也会全表扫描，可优化为值计算：
```
select from order where data <= curdate();
```
或者：
```
select from order where date <= '2017-01-01';
```

### 允许为null的列，查询有潜在大坑
```
select from user where name != 'shenzhen';
```
如果name允许为null，索引不存储null值，结果集中不会包含这些记录
所以，请使用not null约束以及默认值。

### 复合索引最左前缀，并不是指sql语句的where顺序要和复合索引一致
假设用户表建立了login_name，passwd的复合索引

以下写法都能命中索引
```
select from user where login_name = ? and passwd = ?；
select from user where passwd = ? and login_name = ?；
select from user where login_name = ?；// 满足复合索引最左前缀
```
以下下发不能命中索引
```
select from user where passwd = ?  //不满足复合索引最左前缀
```

### 如果明确知道只有一条结果返回，limit 1能够提高效率

```
select from user where login_name = ?;
```
可以优化为
```
select from user where login_name = ? limit 1;
```
你知道只有一条结果，但数据库并不知道，明确告诉它，让它主动停滞游标移动。

---

# 一致性问题

## 冗余表数据一致性问题
数据库水平切分后，通过partition key查询能够很快的定位到库；但非partition key的查询可能会扫描多个库了。
例如订单表，业务上对用户和商家都有订单查询需求：
如果用buyer_id来分库，seller_id的查询就需要扫描多库。如果用seller_id来分库，buyer_id的查询就需要扫描多库。
这种情况，我们一般是通过“数据冗余”的方式来实现。
同一个数据，冗余两份，一份以buyer_id来分库，满足买家的查询需求；一份以seller_id来分库，满足卖家的查询需求。

### 方案1：服务同步写
1. 业务放调用服务，新增数据
2. 服务先插入DB-T1数据
3. 服务再插入DB-T2数据
4. 服务返回业务方新增数据成功

缺点：一次插入变成两次，处理时间翻倍。另外跨库事务无法保证。

### 方案2：服务异步写
数据的双写不再由服务来完成，服务层异步发出一个消息，通过MQ发送给一个专门的数据复制服务来写入冗余数据。

优点：请求处理时间变短（只插入一次）
缺点：引入MQ和数据复制服务，系统复杂性增加。MQ丢失消息的话，冗余表数据会不一致。

### 方案3：线下异步写
数据的双写不再由服务层来完成，而是通过读取DB-T1的binlog来同步到DB-T2

优点：数据双写与业务解耦；请求处理时间变短（只插入一次）
缺点：同步延迟，存在一个数据不一致的时间窗口。数据的一致性依赖于同步任务的可靠性。

### 如何保证数据一致性（线下扫描增量数据）
1. 写入正表T1
2. 第一步写入成功后，写入日志表log1
3. 写入反表T2
4. 第二步成功后，写入日志表log2
然后开启一个离线的扫描工具，不停的比对log1表和log2表，如果发现一致则清除，如果发现数据不一致则补偿修复。


## DB主从架构下数据不一致优化
一主多从，读写分离，冗余多个读库的数据库架构可以提升数据库的读性能，但因为主从同步存在延时，所以有可能读的时候读到的不是最新的数据，怎么解决这个问题？

### 方案1：同步复制优先
1. 系统先写主库
2. 等主从同步完成后，写主库的请求才返回
3. 读从库，读到的时候最新的数据。

缺点：主库的写请求时延增长，吞吐量降低。

### 方案2: 强制读主库
读写都强制走主库，就不存在一致性问题了。

缺点：读写分离的优势没体现出来。

### 方案3：数据库中间件
1. 正常情况写走主库，读走从库；加入中间件后，所有的读写都先通过数据库中间件。
2. 记录所有路由到写库的key，在同步的时间窗口内(假设500ms)，如果有读请求访问中间件，此时从库可能还是旧数据，就把这个key上的读请求路由到主库。
3. 主从同步时间过完后，对应的key的读请求继续路由到从库。

缺点：数据库中间件开发成本较高。

### 方案4：缓存记录写key法（建议）
1. 将某个库上的某个key要发生写操作，记录在cache里，并设置cache超时时间为主从同步时间，例如：500ms
2. 读请求发生的时候，先到cache里查看对应库的对应key有没有相关数据，如果cache有，则说明这个key刚发生过写操作，此时需要将读请求路由到主库读最新的数据；如果cache没有，则说明这个key近期没有发生写操作，此时将请求路由到从库，继续读写分离

缺点：读写数据时多了一步cache操作

---

# 跨库分页方案

## 全局视野法（不推荐）
### 方案实现
1. 将order by time offset X limit Y，改写成order by time offset 0 limit X + Y
2. 服务层将改写后的SQL语句发往各个分库
3. 假设共分为N个库，服务层将得到N * （X + Y）条数据
4. 服务层对得到的N * （X + Y）条数据进行内存排序，内存排序后再取偏移量X后的Y条记录，就是全局视野所需的一页数据。

### 方案优点
通过服务层修改SQL语句，扩大数据召回量，得到全局视野，并精准返回所需数据。

### 方案缺点
1. 每个分库需要返回更多的数据，增大了网络传输量。（耗网络）
2. 服务层需要在内存中进行二次排序，增大了服务层的计算量。（耗CPU）
3. 最致命的是随着页码的增大，需要返回的数据量和排序量大增，性能下降明显。

## 业务折中法一

不提供跳页查询，只提供“下一页”功能。

### 方案实现
1. 第一页记录的max_time会作为第二页数据拉取的查询条件：
order by time offset 100 limit 100 可以改写为 order by time where time > $max_time limit 100
2. 每个分库还是得到2页数据，再使用内存排序，取出前100条数据，作为最终的第二页数据。

### 方案优点
数据的传输量和排序的数据量不会随着不断翻页导致性能下降。

## 业务折中法二
假设分库后，数据在各库中是均衡分布的。

### 方案实现
利用这个原理，要查询全局100页数据，offset 9900 limit 100 可以改写成 offset 4950 limit 50，每个分库偏移4950（一半），获取50条数据（半页），得到的数据集的并集，基本能够认为是全局数据offset 9900 limit 100的数据，当然，这一页数据的精度，并不是精准的。

### 方案优点
不需要返回更多的数据，也不需要在服务端进行内存排序。

## 二次查询法

### 方案步骤
1. 将order by time offset X limit Y，改写成order by time offset X/N limit Y
2. 找到最小值time_min
3. between二次查询，order by time between $time_min and $time_i_max
4. 设置虚拟time_min，找到time_min在各个分库的offset，从而得到time_min在全局的offset
5. 得到了time_min在全局的offset，自然得到了全局的offset X limit Y

### 方案优点
精准返回业务所需数据，不会随着翻页增加数据的返回量

### 方案缺点
需要进行两次数据库查询