# 分布式锁

## 基于数据库
### 实现方法
创建一张表，将其中的某个字段设置为唯一索引，当请求过来的时候只有新建记录成功的请求才算获取到锁，当使用完毕删除这条记录的时候即释放锁。

### 存在的问题
数据库单点问题，挂了怎么办？
不是重入锁，同一进程无法在释放锁之前再次获得锁，因为数据库中已经存在了一条记录了。

锁是非阻塞的，一旦insert失败则会立即返回，并不会进入阻塞队列只能下一次再次获取。

锁没有失效时间，如果那个进程解锁失败那就没有请求可以再次获取锁了。（可以考虑使用定时任务处理）

## 基于Redis
### 实现原理
使用setNX命令，只有当key不存在的才能创建成功，创建成功相当于获取到了锁，可以设置超时时间，过了超时时间会自动删除。

### 存在的问题
如果redis的master节点宕机了，但key又没有同步到slave节点，这就有问题了。

### 开源实现
Redission

## 基于Zookeeper
### 实现原理1
#### 利用节点名称的唯一性来实现共享锁

客户端在指定目录下创建临时有序子节点，如果创建成功表示获得了锁，业务完成后，删除对应的子节点释放锁。如果会话超时，zookeeper也会删除子节点。

#### 存在的问题
当集群很大的时候，许多客户端在等待一把锁，当锁释放的时候，会向客户端发送大量的事件通知，这就是所谓的惊群效应。

### 实现原理2
#### 利用临时顺序节点实现共享锁
zookeeper中有一种节点叫做顺序节点，假如我们创建多个节点，它会按照提起创建的顺序来创建节点，客户端创建节点后调用获取所有节点的方法，如果发现自己是所有节点中最小的，则认为这个客户端获得了锁。

#### 如何防止惊群效应
客户端只监视比自己创建节点小的上一个节点，无需监视所有的。多个客户端共同等待锁，当锁释放时，只有一个客户端会被唤醒。

### 开源实现
curator


# Java中的锁

其实很多锁说的是一个东西，只是从不同的侧重点去看的时候，他们会衍生出不同的名字。

## JDK中实现的锁（ReentrantLock、synchronized）

### 从其他等待的线程是否按顺序获取锁的角度划分（公平锁、非公平锁）

#### 概念理解

我先做个形象比喻，比如现在有一个餐厅，一次最多只允许一个持有钥匙的人进入用餐，那么其他没拿到钥匙的人就要在门口等着，等里面那个人吃完了，他出来他把钥匙扔地上，后边拿到钥匙的人才能进入餐厅用餐。

公平锁：是指多个线程在等待同一个锁时，必须按照申请锁的先后顺序来一次获得锁。所用公平锁就好像在餐厅的门口安装了一个排队的护栏，谁先来的谁就站的靠前，无法进行插队，当餐厅中的人用餐结束后会把钥匙交给排在最前边的那个人，以此类推。公平锁的好处是，可以保证每个排队的人都有饭吃，先到先吃后到后吃。但是弊端是，要额外安装排队装置。

非公平锁：理解了公平锁，非公平锁就很好理解了，它无非就是不用排队，当餐厅里的人出来后将钥匙往地上一扔，谁抢到算谁的。但是这样就造成了一个问题，那些身强体壮的人可能总是会先抢到钥匙，而那些身体瘦小的人可能一直抢不到，这就有可能将一直抢不到钥匙，最后导致需要很长时间才能拿到钥匙甚至一直拿不到直至饿死。

#### 特点总结

1. 公平锁的好处是等待锁的线程不会饿死，但是整体效率相对低一些；非公平锁的好处是整体效率相对高一些，但是有些线程可能会饿死或者说很早就在等待锁，但要等很久才会获得锁。其中的原因是公平锁是严格按照请求所的顺序来排队获得锁的，而非公平锁时可以抢占的，即如果在某个时刻有线程需要获取锁，而这个时候刚好锁可用，那么这个线程会直接抢占，而这时阻塞在等待队列的线程则不会被唤醒。

2. 在java中公平锁可以通过new ReentrantLock(true)来实现；非公平锁可以通过new ReentrantLock(false)或者默认构造函数new ReentrantLock()实现。

3. synchronized是非公平锁，并且它无法实现公平锁。

### 从能否有多个线程能持有一把锁的角度划分（互斥锁）

#### 概念理解
互斥锁就是我们常说的同步，即一次最多只能有一个线程持有的锁，当一个线程持有该锁的时候其它线程无法进入上锁的区域。在Java中synchronized就是互斥锁，从宏观概念来讲，互斥锁就是通过悲观锁的理念引出来的，而非互斥锁则是通过乐观锁的概念引申的。

### 从一个线程能否递归获取自己的锁的角度划分（可重入锁或递归锁、不可重入锁或自旋锁）

我们知道，一条线程若想进入一个被上锁的区域，首先要判断这个区域的锁是否已经被某条线程所持有。如果锁正在被持有那么线程将等待锁的释放，但是这就引发了一个问题，我们来看这样一段简单的代码：

```java
public class ReentrantDemo {
	private Lock mLock;
 
	public ReentrantDemo(Lock mLock) {
		this.mLock = mLock;
	}
 
	public void outer() {
		mLock.lock();
		inner();
		mLock.unlock();
	}
 
	public void inner() {
		mLock.lock();
		// do something
		mLock.unlock();
	}
}
```

当线程A调用outer()方法的时候，会进入使用传进来mlock实例来进行mlock.lock()加锁，此时outer()方法中的这片区域的锁mlock就被线程A持有了，当线程B想要调用outer()方法时会先判断，发现这个mlock这把锁被其它线程持有了，因此进入等待状态。我们现在不考虑线程B，单说线程A，线程A进入outer()方法后，它还要调用inner()方法，并且inner()方法中使用的也是mlock()这把锁，于是接下来有趣的事情就来了。按正常步骤来说，线程A先判断mlock这把锁是否已经被持有了，判断后发现这把锁确实被持有了，但是可笑的是，是A自己持有的。那你说A能否在加了mlock锁的outer()方法中调用加了mlock锁的inner方法呢？答案是如果我们使用的是可重入锁，那么递归调用自己持有的那把锁的时候，是允许进入的。

可重入锁（递归锁）：可以再次进入方法A，就是说在释放锁前此线程可以再次进入方法A（方法A递归）。
不可重入锁（自旋锁）：不可以再次进入方法A，也就是说获得锁进入方法A是此线程在释放锁前唯一的一次进入方法A。

下面这段代码演示了**不可重入锁**：当isLocked被设置为true后，在线程调用unlock()解锁之前不管线程是否已经获得锁，都只能wait()。

```java
public class Lock{  
    private boolean isLocked = false;  
    public synchronized void lock()  
        throws InterruptedException{  
        while(isLocked){  
            wait();  
        }  
        isLocked = true;  
    }  
 
    public synchronized void unlock(){  
        isLocked = false;  
        notify();  
    }  
}  
```

#### 自旋锁
线程自旋，说白了就是占着cpu，让cpu做无用功。
线程阻塞挂起再唤醒的过程会导致线程发生两次上下文切换，如果自旋的消耗小于它的话，那么使用自旋锁是可以提高性能的。
但是如果锁竞争激烈，或者持有锁的线程需要长时间占用锁执行同步块，这时候就不适合使用自旋锁。

JDK1.6开启自旋锁及设置自旋次数，可以通过-XX:+UseSpinning  -XX:PreBlockSpin=10
JDK1.6中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking来禁用偏向锁


### 从编译器优化的角度划分（锁消除、锁粗化、锁膨胀）

锁消除和锁粗化，是编译器在编译代码阶段，对一些没有必要的、不会引起安全问题的同步代码取消同步（锁消除）或者对那些多次执行同步的代码且它们可以可并到一次同步的代码（锁粗化）进行的优化手段，从而提高程序的执行效率。

#### 锁消除

对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行消除。锁消除的主要判断依据是来源于逃逸分析的数据支持，如果判断在一段代码中，堆上的所有数据都不会逃逸出去从而能被其他线程访问到，那就可以把他们当做栈上数据对待，认为他们是线程私有的，同步加锁自然就无需进行。

来看这样一个方法：

```java
public String concatString(String s1, String s2, String s3){
    StringBuffer sb = new StringBuffer();
    sb.append(s1);
    sb.append(s2);
    sb.append(s3);
    return sb.toString();
}
```

源码中StringBuffer 的append方法定义如下：

```java
public synchronized StringBuffer append(StringBuffer sb) {
    super.append(sb);
    return this;
}
```

可见append的方法使用synchronized进行同步，我们知道对象的实例总是存在于堆中被多有线程共享，即使在局部方法中创建的实例依然存在于堆中，但是对该实例的引用是线程私有的，对其他线程不可见。即上边代码中虽然StringBuffer的实例是共享数据，但是对该实例的引用确实每条线程内部私有的。不同的线程引用的是堆中存在的不同的StringBuffer实例，它们互不影响互不可见。也就是说在concatString()方法中涉及了同步操作。但是可以观察到sb对象它的作用域被限制在方法的内部，也就是sb对象不会“逃逸”出去，其他线程无法访问。因此，虽然这里有锁，但是可以被安全的消除，在即时编译之后，这段代码就会忽略掉所有的同步而直接执行了。

#### 锁粗化

原则上，我们在编写代码的时候，总是要将同步块的作用范围限制的尽量小——只在共享数据的实际作用域中才进行同步，这样是为了使得需要同步的操作数量尽可能变小，如果存在锁禁止，那等待的线程也能尽快拿到锁。大部分情况下，这些都是正确的。但是，如果一系列的联系操作都是同一个对象反复加上和解锁，甚至加锁操作是出现在循环体中的，那么即使没有线程竞争，频繁地进行互斥同步操作也导致不必要的性能损耗。

举个案例，类似上面锁消除的concatString()方法。如果StringBuffer sb = new StringBuffer();定义在方法体之外，那么就会有线程竞争，但是每个append()操作都对同一个对象反复加锁解锁，那么虚拟机探测到有这样的情况的话，会把加锁同步的范围扩展到整个操作序列的外部，即扩展到第一个append()操作之前和最后一个append()操作之后，这样的一个锁范围扩展的操作就称之为锁粗化。

#### 锁膨胀
从偏向锁升级到轻量级锁，在升级到重量级锁。这种升级过程叫做锁膨胀。

### 从不同的位置使用synchronized（类锁、对象锁）

这是最常见的锁了，synchronized作为锁来使用的时候，无非就只能出现在两个地方（其实还能修饰变量，但作用是保证可见性，这里讨论锁，故不阐述）：代码块、方法（一般方法、静态方法）。由于可以使用不同的类型来作为锁，因此分成了类锁和对象锁。

类锁：使用字节码文件（即.class）作为锁。如静态同步函数（使用本类的.class），同步代码块中使用.class。
对象锁：使用对象作为锁。如同步函数（使用本类实例，即this），同步代码块中是用引用的对象。

下面代码涵盖了所有synchronized的使用方式：

```java
public class Demo {
	public Object obj = new Object();
 
	public static synchronized void method1() { //1.静态同步函数,使用本类字节码做类锁（即Demo.class）
	}
 
	public void method2() {
		synchronized (Demo.class) { //同步代码块，使用字节码做类锁
		}
	}
 
	public synchronized void method3() { //同步函数，使用本类对象实例即this做对象锁
	}
 
	public void method4() {
		synchronized (this) { //同步代码块，使用本类对象实例即this做对象锁
		}
	}
 
	public void method5() {
		synchronized (obj) { //同步代码块，使用共享数据obj实例做对象锁。
		}
	}
}
```

## 从锁的设计里面来分类（悲观锁、乐观锁）

如果将锁在宏观上进行大的分类，那么所只有两类，即悲观锁和乐观锁。

### 悲观锁

悲观锁是就是悲观思想，即认为写多，遇到并发写的可能性高，每次去拿数据的时候都认为别人会修改，所以每次在读写数据的时候都会上锁，这样别人想读写这个数据就会block直到拿到锁。java中的悲观锁就是Synchronized，AQS框架下的锁则是先尝试cas乐观锁去获取锁，获取不到，才会转换为悲观锁，如ReentrantLock。

### 乐观锁

乐观锁是一种乐观思想，即认为读多写少，遇到并发写的可能性低，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，然后加锁操作（比较跟上一次的版本号，如果一样则更新），如果失败则要重复读-比较-写的操作。

#### 乐观锁的实现思想--CAS（Compare and Set）无锁

CAS并不是一种实际的锁，它仅仅是实现乐观锁的一种思想，java中的乐观锁基本都是通过CAS操作实现的，CAS是一种更新的原子操作，比较当前值跟传入值是否一样，一样则更新，否则失败。

## 数据库中常用到的锁（共享锁、排它锁）

共享锁和排它锁多用于数据库中的事务操作，主要针对读和写的操作。而在Java中，对这组概念通ReentrantReadWriteLock进行了实现，它的理念和数据库中共享锁与排它锁的理念几乎一致，即一条线程进行读的时候，允许其他线程进入上锁的区域中进行读操作；当一条线程进行写操作的时候，不允许其他线程进入进行任何操作。即读+读可以存在，读+写、写+写均不允许存在

### 共享锁
也称**读锁**或**S锁**。如果事务T对数据A加上共享锁后，则其他事务只能对A再加共享锁，不能加排它锁。获准共享锁的事务只能读数据，不能修改数据。

共享锁允许多个线程同时获取锁，并发访问共享资源，如ReadWriteLock。共享锁是一种乐观锁，它放宽了加锁策略，允许多个执行读操作的线程同时访问共享资源。注意：只能允许一个执行写操作的线程访问。

### 排它锁
也称**独占锁**、**写锁**或**X锁**。如果事务T对数据A加上排它锁后，则其他事务不能再对A加任何类型的锁。获得排它锁的事务既能读数据又能修改数据。

独占锁模式下，每次只能有一个线程能持有锁，ReentrantLock是以独占方式实现的互斥锁。独占锁是一种悲观的加锁策略，它避免了读/读冲突，如果某个只读线程获取锁，则其他读线程只能等待，这种情况下就限制了不必要的并发性，因为读操作并不会影响数据的一致性。

## 按锁的效率进行分类（偏向锁、轻量级锁、重量级锁）

由于不同的锁的实现原理不同，故它们的效率肯定也会不尽相同，那么我们在不同的应用场景下究竟该选择何种锁呢？基于这个问题，锁被分成了偏向锁、轻量级锁和重量级锁以便应对不同的应用场景。

### 重量级锁
这种锁依赖于操作系统Mutex Lock实现，操作系统实现线程之间的切换需要从用户态切换到核心态，转换时间较长，成本很高。

### 轻量级锁
使用轻量级锁仅需要将Mark Word中的部分字节CAS更新指向线程栈中的Lock Record，如果更新成功，则轻量级锁获取成功。
否则说明已经有线程获得了轻量级锁，发生了锁竞争，接下来将会升级为重量级锁。

轻量级锁的目标是减少无实际竞争情况下，使用重量级锁产生的性能消耗。比如内核态与用户态的切换。

### 偏向锁
偏向的意思是：假定将来只有第一个申请锁的线程会使用锁（不会再有其他线程来申请锁），本质上也是CAS更新，如果更新成功，则偏向锁获取成功，否则说明有其他线程竞争，接下来将会升级为轻量级锁。

偏向锁的目标是减少无竞争且只有一个线程使用锁的情况下，使用轻量级锁产生的性能消耗。
轻量级锁每次申请、释放锁都至少需要一次CAS，但偏向锁只有初始化时需要一次CAS。

## 由于并发问题产生的锁（死锁、活锁）

### 死锁

所谓死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。下面我通过一些实例来说明死锁现象。

先看生活中的一个实例，2个人一起吃饭但是只有一双筷子，2人轮流吃（同时拥有2只筷子才能吃）。某一个时候，一个拿了左筷子，一人拿了右筷子，2个人都同时占用一个资源，等待另一个资源，这个时候甲在等待乙吃完并释放它占有的筷子，同理，乙也在等待甲吃完并释放它占有的筷子，这样就陷入了一个死循环，谁也无法继续吃饭。

在计算机系统中也存在类似的情况。例如，某计算机系统中只有一台打印机和一台输入 设备，进程P1正占用输入设备，同时又提出使用打印机的请求，但此时打印机正被进程P2 所占用，而P2在未释放打印机之前，又提出请求使用正被P1占用着的输入设备。这样两个进程相互无休止地等待下去，均无法继续执行，此时两个进程陷入死锁状态。

### 活锁

活锁和死锁在表现上是一样的两个线程都没有任何进展，但是区别在于：死锁，两个线程都处于阻塞状态，说白了就是它不会再做任何动作，我们通过查看线程状态是可以分辨出来的。而活锁呢，并不会阻塞，而是一直尝试去获取需要的锁，不断的try，这种情况下线程并没有阻塞所以是活的状态，我们查看线程的状态也会发现线程是正常的，但重要的是整个程序却不能继续执行了，一直在做无用功。举个生动的例子的话，两个人都没有停下来等对方让路，而是都有很有礼貌的给对方让路，但是两个人都在不断朝路的同一个方向移动，这样只是在做无用功，还是不能让对方通过。

